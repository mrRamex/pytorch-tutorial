\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}

\title{Pytorch}
\author{Ramex}
\date{June 2024}

\begin{document}

\lstset{ 
    language=Python,                % choose the language of the code
    numbers=left,                   % where to put the line-numbers
    numberstyle=\tiny\color{gray},  % the style that is used for the line-numbers
    basicstyle=\ttfamily,           % the size of the fonts that are used for the code
    keywordstyle=\color{blue},      % keyword style
    commentstyle=\color{green},     % comment style
    stringstyle=\color{red},        % string literal style
    breaklines=true,                % automatic line breaking
    breakatwhitespace=false,        % don't break at whitespace
    showspaces=false,               % show spaces
    showstringspaces=false,         % underline spaces within strings
}

\maketitle

\section{Tensors}

A Tensor is like an n-dimensional array (multi-dimensional array) 
in numpy, but with additional features. 
A tensor can be created from a list or a numpy array.
The tensor can be converted to a numpy array using the \texttt{numpy()} 
method. The tensor itself can be used for gpu computations.

\subsection{Initializing a Tensor}

A tensor can be initialized by a number of methods, for example:

\begin{itemize}
    \item 1. Directly from data \\
    \texttt{
        data = [[1,2,3],[4,5,6]], \\
        data\_ = torch.tensor(data)
    }
    \item 2. From a numpy array \\
    \texttt{
        data = np.array(data), \\
        data\_x = torch.tensor(data)
    }
    \item 3. From another tensor (creates a copy of the tensor with ones only) \\
    \texttt{torch.ones\_like(x\_data)}
    \item 4. Random or constant values (this takes the shape as input) \\
    \texttt{x\_ones = torch.ones\_like(x\_data)}
\end{itemize}

\subsection{Attributes of a Tensor}

A tensor has the following attributes:
\begin{itemize}
    \item 1. \texttt{shape} : The shape of the tensor
    \item 2. \texttt{dtype} : The data type of the tensor
    \item 3. \texttt{device} : The device on which the tensor is stored
    \item 4. \texttt{size} : The number of elements in the tensor
    \item 5. \texttt{numel} : The number of elements in the tensor
    \item 6. \texttt{T} : The transposed tensor
    \item 7. \texttt{contiguous} : The contiguous tensor
    \item 8. \texttt{view} : The view of the tensor
    \item 9. \texttt{requires\_grad} : The gradient required for the tensor
    \item 10. \texttt{grad} : The gradient of the tensor
    \item more $\dots \Rightarrow$ \href{https://pytorch.org/docs/stable/tensors.html}{Pytorch Documentation}
\end{itemize}

\subsection{Indexing and Slicing}

Indexing and slicing works the same as in numpy. For example:
\begin{itemize}
    \item 1. \texttt{x[0]} : The first element of the tensor
    \item 2. \texttt{x[0,0]} : The first element of the first row
    \item 3. \texttt{x[0,:]} : The first row of the tensor
    \item 4. \texttt{x[:,0]} : The first column of the tensor
    \item 5. \texttt{x[0:2,0:2]} : The first two rows and columns of the tensor
\end{itemize}

\subsection{Joining tensors}

Tensors can be joined using the \texttt{torch.cat()} method. For example:

\begin{itemize}
    \item 1. \texttt{torch.cat([x,y], dim=0)} : Concatenates the tensors along the rows
    \item 2. \texttt{torch.cat([x,y], dim=1)} : Concatenates the tensors along the columns
    \item 3. \texttt{torch.stack([x,y], dim=0)} : Stacks the tensors along the rows
    \item 4. \texttt{torch.stack([x,y], dim=1)} : Stacks the tensors along the columns
\end{itemize}

\subsection{Single-element tensors}

A single-element tensor is a tensor with one element. For example:

\begin{itemize}
    \item 1. \texttt{x.item()} : Returns the value of the tensor as a python number
    \item 2. \texttt{x.tolist()} : Returns the value of the tensor as a python list
    \item 3. \texttt{x.numpy()} : Returns the value of the tensor as a numpy array
    \item 4. \texttt{x.to(device)} : Moves the tensor to the specified device
\end{itemize}

\subsection{Tensor to NumPy array}

A tensor can be converted to a numpy array using the \texttt{numpy()} method. Example:

\begin{itemize}
    \item 1. \texttt{x.numpy()} : Converts the tensor to a numpy array
    \item 2. \texttt{x.cpu().numpy()} : Converts the tensor to a numpy array on the cpu
    \item 3. \texttt{x.cuda().numpy()} : Converts the tensor to a numpy array on the gpu
\end{itemize}

\section{Datasets \& DataLoaders}

\subsection{Loading a Dataset}

Loading datasets in PyTorch involves using the torch.utils.data module, which provides utilities for efficiently loading and processing data. The key components 
include Dataset and DataLoader.
\subsubsection{Key Components}

\begin{itemize}
    \item 1. Dataset: An abstract class representing a dataset. You need to subclass this and implement two methods:
    \item 1.1. \_\_len\_\_: Returns the size of the dataset.
    \item 1.2. \_\_getitem\_\_: Supports indexing such that dataset[i] can be used to get the ith sample.
    \item 2. DataLoader: Combines a dataset and a sampler, and provides an iterable over the given dataset. It supports batching, shuffling, and parallel data loading.
\end{itemize}

\subsubsection{Example: Loading a Custom Dataset}
Let's go through an example of creating a custom dataset and loading it using PyTorch.

\subsubsection{Step 1: Import Required Libraries}

\begin{lstlisting}
import torch
from torch.utils.data import Dataset, DataLoader
import pandas as pd
from sklearn.preprocessing import LabelEncoder

\end{lstlisting}

\subsubsection{Step 2: Create a Custom Dataset}
Assume we have a CSV file data.csv with the following structure:
\begin{lstlisting}
text,label
"I love PyTorch", positive
"I hate bugs", negative

\end{lstlisting}

We will create a custom dataset to load this data.

\begin{lstlisting}
    class TextDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.texts = self.data['text'].values
        self.labels = self.data['label'].values
        
        # Encode labels as integers
        self.label_encoder = LabelEncoder()
        self.labels = self.label_encoder.fit_transform(self.labels)

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = self.texts[idx]
        label = self.labels[idx]
        return text, label

\end{lstlisting}

\subsubsection{Step 3: Instantiate the Dataset and DataLoader}

\begin{lstlisting}
# Create an instance of the dataset
dataset = TextDataset(csv_file='data.csv')

# Create a DataLoader for the dataset
dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=2)

\end{lstlisting}

\subsubsection{Explanation of DataLoader Parameters}

\begin{itemize}
    \item dataset: The dataset from which to load the data.
    \item batch\_size: How many samples per batch to load.
    \item shuffle: Set to True to have the data reshuffled at every epoch.
    \item num\_workers: How many subprocesses to use for data loading. 0 means that the data will be loaded in the main process.
\end{itemize}

\subsection{Step 4: Iterate Through the DataLoader}

A dataset can be iterated over using a for loop. For example:

\begin{lstlisting}
    for batch in dataloader:
    texts, labels = batch
    print(texts)
    print(labels)
\end{lstlisting}

\subsection{Using Built-In Datasets}

PyTorch also provides utilities for loading several standard datasets, such as MNIST, CIFAR-10, and ImageNet, through the torchvision package.

\subsubsection{Example: Loading the MNIST Dataset}

\begin{lstlisting}
import torchvision.transforms as transforms
from torchvision.datasets import MNIST

# Define a transform to normalize the data
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

# Download and load the training dataset
train_dataset = MNIST(root='mnist_data', train=True, download=True, transform=transform)

# Create a DataLoader for the training dataset
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)

# Iterate through the DataLoader
for batch in train_loader:
    images, labels = batch
    print(images.shape)
    print(labels)
    break

\end{lstlisting}

\section{Transforms}

Transformers are a type of neural network architecture designed for 
handling sequential data, such as text. They have become a cornerstone of 
modern natural language processing (NLP) due to their ability to capture 
long-range dependencies and parallelize training. Here’s an explanation of 
Transformers and how to implement them using PyTorch.\\

\subsection{Transformer Architecture}

The Transformer model was introduced in the paper "Attention is All You 
Need" by Vaswani et al. in 2017. It consists of an encoder-decoder 
structure, where both the encoder and decoder are composed of a stack of 
identical layers.

\subsection{Key Components}

\begin{itemize}
    \item 1. Multi-Head Self-Attention Mechanism: Allows the model to focus on different parts of the input sequence simultaneously.
    \item 2. Positional Encoding: Adds information about the position of words in the sequence.
    \item 3. Feed-Forward Neural Network: Applied to each position separately and identically.
    \item 4. Layer Normalization and Residual Connections: Improve training dynamics by normalizing intermediate layers and adding shortcuts to skip connections.
\end{itemize}

\subsection{PyTorch Implementation}

PyTorch provides a built-in module for the Transformer model through torch.nn.Transformer. Here’s a step-by-step guide to implementing a basic Transformer 
model in PyTorch.

\subsubsection{Step 1: Import Required Libraries}

\begin{lstlisting}
    import torch
    import torch.nn as nn
    import torch.optim as optim
    import math    
\end{lstlisting}
    
\subsubsection*{Step 2: Positional Encoding}
Positional encoding helps the model to understand the order of the sequence.

\begin{lstlisting}
    class PositionalEncoding(nn.Module):
    def __init__(self, d_model, max_len=5000):
        super(PositionalEncoding, self).__init__()
        self.pe = torch.zeros(max_len, d_model).unsqueeze(0)
        position = torch.arange(0, max_len).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))
        self.pe[:, :, 0::2] = torch.sin(position * div_term)
        self.pe[:, :, 1::2] = torch.cos(position * div_term)

    def forward(self, x):
        x = x + self.pe[:, :x.size(1)]
        return x
\end{lstlisting}

\subsubsection*{Step 3: Transformer Model}

\begin{lstlisting}
    class TransformerModel(nn.Module):
    def __init__(self, input_dim, model_dim, output_dim, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, max_seq_length):
        super(TransformerModel, self).__init__()
        self.model_type = 'Transformer'
        self.pos_encoder = PositionalEncoding(model_dim, max_seq_length)
        self.encoder = nn.Embedding(input_dim, model_dim)
        self.decoder = nn.Embedding(output_dim, model_dim)
        self.transformer = nn.Transformer(d_model=model_dim, nhead=nhead, 
            num_encoder_layers=num_encoder_layers,
            num_decoder_layers=num_decoder_layers, dim_feedforward=dim_feedforward)
        self.fc_out = nn.Linear(model_dim, output_dim)
        self.model_dim = model_dim

    def forward(self, src, tgt, src_mask=None, tgt_mask=None):
        src = self.encoder(src) * math.sqrt(self.model_dim)
        tgt = self.decoder(tgt) * math.sqrt(self.model_dim)
        src = self.pos_encoder(src)
        tgt = self.pos_encoder(tgt)
        output = self.transformer(src, tgt, src_mask, tgt_mask)
        output = self.fc_out(output)
        return output
\end{lstlisting}

\subsubsection*{Step 4: Example Usage}

\begin{lstlisting}
    # Define the model parameters
input_dim = 1000  # Size of the input vocabulary
model_dim = 512   # Dimension of the model
output_dim = 1000 # Size of the output vocabulary
nhead = 8         # Number of attention heads
num_encoder_layers = 6
num_decoder_layers = 6
dim_feedforward = 2048
max_seq_length = 100

# Instantiate the model
model = TransformerModel(input_dim, model_dim, output_dim, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, max_seq_length)

# Define input and output sequences (batch_size, sequence_length)
src = torch.randint(0, input_dim, (10, 32))  # Example source sequence
tgt = torch.randint(0, output_dim, (10, 32)) # Example target sequence

# Forward pass
output = model(src, tgt)

print(output.shape)  # Output shape will be (sequence_length, batch_size, output_dim)
\end{lstlisting}

\section{Build the Neural Network}

\begin{lstlisting}
import os   # import the os library
import torch    # import the torch library
from torch import nn    # import the nn library from torch
from torch.utils.data import DataLoader # import the DataLoader class
from torchvision import datasets, transforms # import the datasets and transforms library
\end{lstlisting}

\subsection{Get Device for Training}

\begin{lstlisting}
device = (
    "cuda" if torch.cuda.is_available() # check if GPU is available
    else "mps" # use CPU in case GPU is not available
    if torch.backends.mps.is_available() # check if multi-process service is available
    else "cpu" # use CPU in case multi-process service is not available
    else "cpu"
)
print(f"Using {device} device")
\end{lstlisting}

\subsection{Define the Class}

We define our neural network by subclassing nn.Module, and initialize the 
neural network layers in \_\_init\_\_. Every nn.Module subclass implements the 
operations on input data in the forward method.

\begin{lstlisting}
class NeuralNetwork(nn.Module):
    def __init__(self):
        super().__init__()
        self.flatten = nn.Flatten()
        self.linear_relu_stack = nn.Sequential(
            nn.Linear(28*28, 512),
            nn.ReLU(),
            nn.Linear(512, 512),
            nn.ReLU(),
            nn.Linear(512, 10),
        )

    def forward(self, x):
        x = self.flatten(x)
        logits = self.linear_relu_stack(x)
        return logits
\end{lstlisting}

\subsection{Model Layers}

\begin{lstlisting}
input_image = torch.rand(3,28,28)
print(input_image.size())
\end{lstlisting}

\begin{lstlisting}
flatten = nn.Flatten()
flat_image = flatten(input_image)
print(flat_image.size())
\end{lstlisting}

\begin{lstlisting}
layer1 = nn.Linear(in_features=28*28, out_features=20)
hidden1 = layer1(flat_image)
print(hidden1.size())
\end{lstlisting}

\begin{lstlisting}
print(f"Before ReLU: {hidden1}\n\n")
hidden1 = nn.ReLU()(hidden1)
print(f"After ReLU: {hidden1}")
\end{lstlisting}

\begin{lstlisting}
seq_modules = nn.Sequential(
    flatten,
    layer1,
    nn.ReLU(),
    nn.Linear(20, 10)
)
input_image = torch.rand(3,28,28)
logits = seq_modules(input_image)
\end{lstlisting}

\begin{lstlisting}
softmax = nn.Softmax(dim=1)
pred_probab = softmax(logits)
\end{lstlisting}

\begin{lstlisting}
print(f"Model structure: {model}\n\n")

for name, param in model.named_parameters():
    print(f"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \n")
\end{lstlisting}

\section{Automatic Differentiation with torch.autograd}

\section{Optimizing Model Parameters}

Now that we have a model and data it’s time to train, validate and test our 
model by optimizing its parameters on our data. Training a model is an 
iterative process; in each iteration the model makes a guess about the 
output, calculates the error in its guess (loss), collects the derivatives 
of the error with respect to its parameters (as we saw in the previous 
section), and optimizes these parameters using gradient descent. For a 
more detailed walkthrough of this process, check out this video on 
\href[]{https://www.youtube.com/watch?v=tIeHLnjs5U8}{backpropagation from 3Blue1Brown.}

\subsection{Prerequisite Code}

\begin{lstlisting}
import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets
from torchvision.transforms import ToTensor

training_data = datasets.FashionMNIST(
    root="data",
    train=True,
    download=True,
    transform=ToTensor()
)

test_data = datasets.FashionMNIST(
    root="data",
    train=False,
    download=True,
    transform=ToTensor()
)

train_dataloader = DataLoader(training_data, batch_size=64)
test_dataloader = DataLoader(test_data, batch_size=64)

class NeuralNetwork(nn.Module):
    def __init__(self):
        super().__init__()
        self.flatten = nn.Flatten()
        self.linear_relu_stack = nn.Sequential(
            nn.Linear(28*28, 512),
            nn.ReLU(),
            nn.Linear(512, 512),
            nn.ReLU(),
            nn.Linear(512, 10),
        )

    def forward(self, x):
        x = self.flatten(x)
        logits = self.linear_relu_stack(x)
        return logits

model = NeuralNetwork()
\end{lstlisting}

\subsection{Hyperparameters}

Hyperparameters are adjustable parameters that let you control the model 
optimization process. Different hyperparameter values can impact model 
training and convergence rates.

We define the following hyperparameters for training:

\begin{itemize}
    \item Number of Epochs - the number times to iterate over the dataset
    \item Batch Size - the number of data samples propagated through the network before the parameters are updated
    \item Learning Rate - how much to update models parameters at each batch/epoch. Smaller values yield slow learning speed, while large values may result in unpredictable behavior during training.
\end{itemize}

\begin{lstlisting}
learning_rate = 1e-3
batch_size = 64
epochs = 5
\end{lstlisting}

\subsection{Optimization Loop}

Once we set our hyperparameters, we can then train and optimize our model 
with an optimization loop. Each iteration of the optimization loop is 
called an epoch.

Each epoch consists of two main parts:

\begin{itemize}
    \item The Train Loop - iterate over the training dataset and try to converge to optimal parameters.
    \item The Validation/Test Loop - iterate over the test dataset to check if model performance is improving.
\end{itemize}

\subsection{Loss Function}

When presented with some training data, our untrained network is likely 
not to give the correct answer. Loss function measures the degree of 
dissimilarity of obtained result to the target value, and it is the loss 
function that we want to minimize during training. To calculate the loss 
we make a prediction using the inputs of our given data sample and compare 
it against the true data label value.

Common loss functions include \href[]{https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss}{nn.MSELoss} (Mean Square Error) for regression 
tasks, and \href[]{https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss}{nn.NLLLoss} (Negative Log Likelihood) for classification. 
\href[]{https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss}{nn.CrossEntropyLoss} combines nn.LogSoftmax and nn.NLLLoss.
\\\\
We pass our model’s output logits to nn.CrossEntropyLoss, which will normalize the 
logits and compute the prediction error.

\begin{lstlisting}
# Initialize the loss function
loss_fn = nn.CrossEntropyLoss()
\end{lstlisting}

\subsection{Optimizer}

Optimization is the process of adjusting model parameters to reduce model error in 
each training step. Optimization algorithms define how this process is performed 
(in this example we use Stochastic Gradient Descent). All optimization logic is 
encapsulated in the optimizer object. Here, we use the SGD optimizer; additionally, 
there are many \href[]{https://pytorch.org/docs/stable/optim.html}{different optimizers} available in PyTorch such as ADAM and RMSProp, 
that work better for different kinds of models and data.
\\\\
We initialize the optimizer by registering the model’s parameters that need to be 
trained, and passing in the learning rate hyperparameter.

\begin{lstlisting}
optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)
\end{lstlisting}

Inside the training loop, optimization happens in three steps:

\begin{itemize}
    \item Call optimizer.zero\_grad() to reset the gradients of model parameters. Gradients by default add up; to prevent double-counting, we explicitly zero them at each iteration.
    \item Backpropagate the prediction loss with a call to loss.backward(). PyTorch deposits the gradients of the loss w.r.t. each parameter.
    \item Once we have our gradients, we call optimizer.step() to adjust the parameters by the gradients collected in the backward pass.
\end{itemize}

\subsection{Full Implementation}

We define train\_loop that loops over our optimization code, and test\_loop that 
evaluates the model’s performance against our test data.

\begin{lstlisting}
def train_loop(dataloader, model, loss_fn, optimizer):
    size = len(dataloader.dataset)
    # Set the model to training mode - important for batch normalization and dropout layers
    # Unnecessary in this situation but added for best practices
    model.train()
    for batch, (X, y) in enumerate(dataloader):
        # Compute prediction and loss
        pred = model(X)
        loss = loss_fn(pred, y)

        # Backpropagation
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()

        if batch % 100 == 0:
            loss, current = loss.item(), batch * batch_size + len(X)
            print(f"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]")


def test_loop(dataloader, model, loss_fn):
    # Set the model to evaluation mode - important for batch normalization and dropout layers
    # Unnecessary in this situation but added for best practices
    model.eval()
    size = len(dataloader.dataset)
    num_batches = len(dataloader)
    test_loss, correct = 0, 0

    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode
    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True
    with torch.no_grad():
        for X, y in dataloader:
            pred = model(X)
            test_loss += loss_fn(pred, y).item()
            correct += (pred.argmax(1) == y).type(torch.float).sum().item()

    test_loss /= num_batches
    correct /= size
    print(f"Test Error: \n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \n")

loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)

epochs = 10
for t in range(epochs):
    print(f"Epoch {t+1}\n-------------------------------")
    train_loop(train_dataloader, model, loss_fn, optimizer)
    test_loop(test_dataloader, model, loss_fn)
print("Done!")
\end{lstlisting}

\section{Save and Load the Model}

In this section we will look at how to persist model state with saving, loading and 
running model predictions.

\begin{lstlisting}
import torch
import torchvision.models as models
\end{lstlisting}

\subsection{Saving and Loading Model Weights}

PyTorch models store the learned parameters in an internal state dictionary, 
called state\_dict. These can be persisted via the torch.save method:

\begin{lstlisting}
model = models.vgg16(weights='IMAGENET1K_V1')
torch.save(model.state_dict(), 'model_weights.pth')
\end{lstlisting}

To load model weights, you need to create an instance of the same model first, and 
then load the parameters using load\_state\_dict() method.

\begin{lstlisting}
model = models.vgg16() # we do not specify ``weights``, i.e. create untrained model
model.load_state_dict(torch.load('model_weights.pth'))
model.eval()
\end{lstlisting}

\subsection{Saving and Loading Models with Shapes}

When loading model weights, we needed to instantiate the model class first, because the 
class defines the structure of a network. We might want to save the structure of this 
class together with the model, in which case we can pass model 
(and not model.state\_dict()) to the saving function:

\begin{lstlisting}
torch.save(model, 'model.pth')
\end{lstlisting}

We can then load the model like this:

\begin{lstlisting}
model = torch.load('model.pth')
\end{lstlisting}



\end{document}
